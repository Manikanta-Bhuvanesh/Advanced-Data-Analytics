library(tidyverse)
library(SnowballC)
library(tm)
df<-read.csv("Sentiment.csv")
summary(df)
head(df)
df<-df[c(16,6)]
head(df)
str(df)
round(prop.table(table(df$sentiment)),2)
corpus <- VCorpus(VectorSource(df$text))
as.character(corpus[[1]])
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stemDocument)
corpus <- tm_map(corpus, stripWhitespace)
as.character(corpus[[1]])
dtm <- DocumentTermMatrix(corpus)
dtm
dim(dtm)
dtm <- removeSparseTerms(dtm, 0.999)
dim(dtm)
inspect(dtm[0:10, 1:15])
freq<- sort(colSums(as.matrix(dtm)), decreasing=TRUE)
findFreqTerms(dtm, lowfreq=60)
library(ggplot2)
wf<- data.frame(word=names(freq), freq=freq)
head(wf)
